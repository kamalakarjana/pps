name: lbg App CI/CD

on:
  push:
    branches: [main, qwert]
  pull_request:
    branches: [main]

env:
  ACR_NAME: "acrlbgdemodev2025"
  AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  NODE_VERSION: '18'
  TERRAFORM_VERSION: '1.5.0'
  HELM_VERSION: '3.14.0'

jobs:
  Build-terraform-infrastructure:
    runs-on: ubuntu-latest
    environment: dev
    steps:
      - uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Terraform Init
        run: |
          cd infrastructure
          terraform init -reconfigure \
            -backend-config="resource_group_name=rg-lbg-demo-dev" \
            -backend-config="storage_account_name=tfstatestorageacc2b22" \
            -backend-config="container_name=lbg-02-12-1994" \
            -backend-config="key=terraform.tfstate"
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      - name: Import Existing Resources
        run: |
          cd infrastructure
          
          # Function to import resource with error handling
          import_resource() {
            echo "Importing $1..."
            terraform import $2 $3 || echo "‚ö†Ô∏è  Import failed for $1 (may not exist or already imported)"
          }
          
          # Import all resources (continue on error for each)
          import_resource "Resource Group" "azurerm_resource_group.main" "/subscriptions/$AZURE_SUBSCRIPTION_ID/resourceGroups/rg-lbg-demo-dev"
          import_resource "Container Registry" "azurerm_container_registry.main" "/subscriptions/$AZURE_SUBSCRIPTION_ID/resourceGroups/rg-lbg-demo-dev/providers/Microsoft.ContainerRegistry/registries/$ACR_NAME"
          import_resource "Virtual Network" "azurerm_virtual_network.main" "/subscriptions/$AZURE_SUBSCRIPTION_ID/resourceGroups/rg-lbg-demo-dev/providers/Microsoft.Network/virtualNetworks/vnet-dev-lbg-app"
          import_resource "Subnet" "azurerm_subnet.aks" "/subscriptions/$AZURE_SUBSCRIPTION_ID/resourceGroups/rg-lbg-demo-dev/providers/Microsoft.Network/virtualNetworks/vnet-dev-lbg-app/subnets/aks-subnet"
          import_resource "AKS Cluster" "azurerm_kubernetes_cluster.main" "/subscriptions/$AZURE_SUBSCRIPTION_ID/resourceGroups/rg-lbg-demo-dev/providers/Microsoft.ContainerService/managedClusters/lbg-aks-cluster-dev"
          import_resource "Public IP" "azurerm_public_ip.pip" "/subscriptions/$AZURE_SUBSCRIPTION_ID/resourceGroups/rg-lbg-demo-dev/providers/Microsoft.Network/publicIPAddresses/pip-lb-dev-lbg-app"
          
          echo "‚úÖ Resource import process completed"
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ACR_NAME: ${{ env.ACR_NAME }}

      - name: Terraform Validate
        run: |
          cd infrastructure
          terraform validate
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      - name: Terraform Format
        run: |
          cd infrastructure
          terraform fmt -recursive

      - name: Terraform Plan
        run: |
          cd infrastructure
          terraform plan \
            -var="environment=dev" \
            -var="resource_group_name=rg-lbg-demo-dev" \
            -var="location=Central US" \
            -var="acr_name=${{ env.ACR_NAME }}" \
            -var="aks_cluster_name=lbg-aks-cluster" \
            -var="vnet_name=vnet-dev-lbg-app" \
            -var="public_ip_name=pip-lb-dev-lbg-app" \
            -var="vm_size=Standard_D2s_v3" \
            -var="kubernetes_version=1.33.3" \
            -var="min_count=1" \
            -var="max_count=5" \
            -out=tfplan
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/qwert'
        run: |
          cd infrastructure
          echo "Applying Terraform plan on branch: ${{ github.ref }}"
          terraform apply -auto-approve tfplan
          echo "Terraform apply completed successfully"
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

  build-and-push:
    runs-on: ubuntu-latest
    needs: Build-terraform-infrastructure
    strategy:
      matrix:
        service: [patient-service, appointment-service]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies for ${{ matrix.service }}
        run: |
          cd ${{ matrix.service }}
          npm install

      - name: Run tests for ${{ matrix.service }}
        run: |
          cd ${{ matrix.service }}
          npm test || echo "Tests completed with warnings"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Azure Container Registry
        run: |
          az login --service-principal \
            -u ${{ secrets.AZURE_CLIENT_ID }} \
            -p ${{ secrets.AZURE_CLIENT_SECRET }} \
            --tenant ${{ secrets.AZURE_TENANT_ID }}
          az acr login --name ${{ env.ACR_NAME }}

      - name: Build and Push Docker image for ${{ matrix.service }}
        run: |
          cd ${{ matrix.service }}
          
          # Build the image
          docker build \
            --tag ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:${{ github.sha }} \
            --tag ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:latest \
            --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
            --build-arg VCS_REF=${{ github.sha }} \
            --build-arg VERSION=1.0.0 \
            .
          
          # Push the image
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:${{ github.sha }}
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:latest
          
          echo "Successfully built and pushed ${{ matrix.service }}:${{ github.sha }}"

  trivy-scan:
    runs-on: ubuntu-latest
    needs: build-and-push
    strategy:
      matrix:
        service: [patient-service, appointment-service]
    steps:
      - name: Log in to Azure Container Registry
        run: |
          az login --service-principal \
            -u ${{ secrets.AZURE_CLIENT_ID }} \
            -p ${{ secrets.AZURE_CLIENT_SECRET }} \
            --tenant ${{ secrets.AZURE_TENANT_ID }}
          az acr login --name ${{ env.ACR_NAME }}

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.24.0
        with:
          image-ref: '${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:${{ github.sha }}'
          format: 'table'
          severity: 'CRITICAL,HIGH'
          exit-code: 1

      - name: Upload Trivy results as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-results-${{ matrix.service }}
          path: |
            trivy-results-*.json
            trivy-results-*.sarif
          retention-days: 30

  security-scan:
    runs-on: ubuntu-latest
    needs: build-and-push
    steps:
      - uses: actions/checkout@v4

      - name: Run npm audit
        run: |
          echo "Running npm audit for patient-service..."
          cd patient-service && npm audit --audit-level high || echo "npm audit completed with warnings"
          echo "Running npm audit for appointment-service..."
          cd ../appointment-service && npm audit --audit-level high || echo "npm audit completed with warnings"

  deploy-to-dev:
    runs-on: ubuntu-latest
    needs: [Build-terraform-infrastructure, trivy-scan, security-scan]
    environment: dev
    steps:
      - uses: actions/checkout@v4

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh --version v${{ env.HELM_VERSION }}
          helm version

      - name: Configure Azure credentials
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group rg-lbg-demo-dev \
            --name lbg-aks-cluster-dev \
            --overwrite-existing

      - name: Setup Kubernetes context
        run: |
          kubectl config current-context
          kubectl get nodes

      - name: Install Nginx Ingress Controller
        run: |
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --set controller.service.type=LoadBalancer \
            --set controller.ingressClassResource.name=nginx \
            --set controller.ingressClassResource.controllerValue="k8s.io/ingress-nginx" \
            --wait \
            --timeout 5m

      - name: Wait for LoadBalancer IP
        run: |
          echo "Waiting for LoadBalancer IP assignment..."
          timeout 300s bash -c 'until kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath="{.status.loadBalancer.ingress[0].ip}" | grep -q "."; do sleep 5; done'
          EXTERNAL_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "External IP: $EXTERNAL_IP"
          echo "external_ip=$EXTERNAL_IP" >> $GITHUB_ENV

      - name: Handle existing namespace
        run: |
          # Check if namespace exists
          if kubectl get namespace lbg-ns >/dev/null 2>&1; then
            echo "Namespace lbg-ns already exists"
            
            # Check if there's a Helm release in this namespace
            if helm list -n lbg-ns -q | grep -q "lbg-app"; then
              echo "Helm release 'lbg-app' exists, will perform upgrade"
            else
              echo "No Helm release found. Deleting namespace for clean installation..."
              kubectl delete namespace lbg-ns
              echo "Waiting for namespace to be deleted..."
              sleep 30
            fi
          else
            echo "Namespace lbg-ns does not exist, it will be created"
          fi

      - name: Create ACR pull secret
        run: |
          # Ensure namespace exists
          kubectl create namespace lbg-ns --dry-run=client -o yaml | kubectl apply -f -
          
          # Create or update ACR secret
          kubectl create secret docker-registry acr-secret \
            --namespace lbg-ns \
            --docker-server=${{ env.ACR_NAME }}.azurecr.io \
            --docker-username=${{ secrets.AZURE_CLIENT_ID }} \
            --docker-password=${{ secrets.AZURE_CLIENT_SECRET }} \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy to AKS using Helm
        run: |
          cd kubernetes/helm
          
          # Template test first
          helm template lbg-app . \
            --namespace lbg-ns \
            -f values-dev.yml \
            --set patientService.tag=${{ github.sha }} \
            --set appointmentService.tag=${{ github.sha }} \
            --set image.registry=${{ env.ACR_NAME }}.azurecr.io
          
          # Install/Upgrade the release
          helm upgrade --install lbg-app . \
            --namespace lbg-ns \
            --create-namespace \
            --wait \
            --timeout 15m \
            -f values-dev.yml \
            --set patientService.tag=${{ github.sha }} \
            --set appointmentService.tag=${{ github.sha }} \
            --set image.registry=${{ env.ACR_NAME }}.azurecr.io \
            --atomic

      - name: Verify deployment
        run: |
          echo "=== Deployment Verification ==="
          kubectl get all -n lbg-ns
          echo ""
          kubectl get ingress -n lbg-ns
          echo ""
          kubectl get hpa -n lbg-ns 2>/dev/null || echo "HPA not configured"

      - name: Get Browser Access URLs
        run: |
          EXTERNAL_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "üéâ DEPLOYMENT SUCCESSFUL!"
          echo ""
          echo "üì± BROWSER ACCESS INFORMATION:"
          echo "================================"
          echo "External IP: $EXTERNAL_IP"
          echo ""
          echo "üìç Add this to your /etc/hosts file:"
          echo "$EXTERNAL_IP lbg-app.dev.local"
          echo ""
          echo "üåê Access your services in browser:"
          echo "   Patient Service:    http://lbg-app.dev.local/patients"
          echo "   Appointment Service: http://lbg-app.dev.local/appointments" 
          echo "   Health Check:       http://lbg-app.dev.local/health"

      - name: Run comprehensive health checks
        run: |
          echo "=== Running Health Checks ==="
          
          # Wait for pods to be ready
          echo "Waiting for pods to be ready..."
          kubectl wait --for=condition=ready pod -l app=patient-service -n lbg-ns --timeout=300s
          kubectl wait --for=condition=ready pod -l app=appointment-service -n lbg-ns --timeout=300s
          
          # Test through ingress
          echo "Testing through ingress..."
          EXTERNAL_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          if [ -n "$EXTERNAL_IP" ]; then
            curl -s -f http://$EXTERNAL_IP/health && echo "‚úÖ Ingress health check: OK" || echo "‚ùå Ingress health check: FAILED"
          fi

  cleanup:
    runs-on: ubuntu-latest
    if: always()
    needs: [deploy-to-dev]
    steps:
      - name: Cleanup Docker images
        run: |
          docker system prune -f
