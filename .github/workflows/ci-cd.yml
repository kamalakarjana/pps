name: lbg App CI/CD

on:
  push:
    branches: [main, pps-sat]
  pull_request:
    branches: [main, pps-sat]

env:
  ACR_NAME: "acrlbgdemodev2025"
  AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  NODE_VERSION: '18'
  TERRAFORM_VERSION: '1.5.0'
  HELM_VERSION: '3.14.0'

jobs:
  Build-terraform-infrastructure:
    runs-on: ubuntu-latest
    environment: dev
    steps:
      - uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Terraform Init
        run: |
          cd infrastructure
          terraform init \
            -backend-config="resource_group_name=rg-lbg-demo-dev" \
            -backend-config="storage_account_name=tfstatestorageacc2b22" \
            -backend-config="container_name=lbg-02-12-1994" \
            -backend-config="key=terraform.tfstate"
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      - name: Terraform Validate
        run: |
          cd infrastructure
          terraform validate
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      - name: Terraform Format
        run: |
          cd infrastructure
          terraform fmt -recursive

      - name: Terraform Plan
        run: |
          cd infrastructure
          terraform plan \
            -var="environment=dev" \
            -var="resource_group_name=rg-lbg-demo-dev" \
            -var="location=Central US" \
            -var="acr_name=${{ env.ACR_NAME }}" \
            -var="aks_cluster_name=lbg-aks-cluster" \
            -var="vnet_name=vnet-dev-lbg-app" \
            -var="public_ip_name=pip-lb-dev-lbg-app" \
            -var="vm_size=Standard_D2s_v3" \
            -var="kubernetes_version=1.33.3" \
            -var="min_count=1" \
            -var="max_count=5" \
            -out=tfplan
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/pps-sat'
        run: |
          cd infrastructure
          echo "Applying Terraform plan on branch: ${{ github.ref }}"
          terraform apply -auto-approve tfplan
          echo "Terraform apply completed successfully"
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

  build-and-push:
    runs-on: ubuntu-latest
    needs: Build-terraform-infrastructure
    strategy:
      matrix:
        service: [patient-service, appointment-service]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies for ${{ matrix.service }}
        run: |
          cd ${{ matrix.service }}
          npm install

      - name: Run tests for ${{ matrix.service }}
        run: |
          cd ${{ matrix.service }}
          npm test || echo "Tests completed with warnings"

      - name: Test application locally
        run: |
          cd ${{ matrix.service }}
          timeout 10s npm start &
          sleep 5
          curl -f http://localhost:${{ matrix.service == 'patient-service' && '3000' || '3001' }}/health || echo "Local health check failed but continuing"
          pkill -f "node"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Azure Container Registry
        run: |
          az login --service-principal \
            -u ${{ secrets.AZURE_CLIENT_ID }} \
            -p ${{ secrets.AZURE_CLIENT_SECRET }} \
            --tenant ${{ secrets.AZURE_TENANT_ID }}
          az acr login --name ${{ env.ACR_NAME }}

      - name: Build and Push Docker image for ${{ matrix.service }}
        run: |
          cd ${{ matrix.service }}
          
          # Build the image
          docker build \
            --tag ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:${{ github.sha }} \
            --tag ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:latest \
            .
          
          # Push the image
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:${{ github.sha }}
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:latest
          
          echo "Successfully built and pushed ${{ matrix.service }}:${{ github.sha }}"

  trivy-scan:
    runs-on: ubuntu-latest
    needs: build-and-push
    strategy:
      matrix:
        service: [patient-service, appointment-service]
    steps:
      - name: Log in to Azure Container Registry
        run: |
          az login --service-principal \
            -u ${{ secrets.AZURE_CLIENT_ID }} \
            -p ${{ secrets.AZURE_CLIENT_SECRET }} \
            --tenant ${{ secrets.AZURE_TENANT_ID }}
          az acr login --name ${{ env.ACR_NAME }}

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.24.0
        with:
          image-ref: '${{ env.ACR_NAME }}.azurecr.io/${{ matrix.service }}:${{ github.sha }}'
          format: 'table'
          severity: 'CRITICAL'
          exit-code: 1

  security-scan:
    runs-on: ubuntu-latest
    needs: build-and-push
    steps:
      - uses: actions/checkout@v4

      - name: Run npm audit
        run: |
          echo "Running npm audit for patient-service..."
          cd patient-service && npm audit --audit-level high || echo "npm audit completed with warnings"
          echo "Running npm audit for appointment-service..."
          cd ../appointment-service && npm audit --audit-level high || echo "npm audit completed with warnings"

  deploy-to-dev:
    runs-on: ubuntu-latest
    needs: [Build-terraform-infrastructure, trivy-scan, security-scan]
    environment: dev
    steps:
      - uses: actions/checkout@v4

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh --version v${{ env.HELM_VERSION }}
          helm version

      - name: Configure Azure credentials
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group rg-lbg-demo-dev \
            --name lbg-aks-cluster-dev \
            --overwrite-existing

      - name: Setup Kubernetes context
        run: |
          kubectl config current-context
          kubectl get nodes

      - name: Get ACR Admin Credentials
        id: get_acr_credentials
        run: |
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query "username" -o tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query "passwords[0].value" -o tsv)
          echo "acr_username=$ACR_USERNAME" >> $GITHUB_OUTPUT
          echo "acr_password=$ACR_PASSWORD" >> $GITHUB_OUTPUT

      - name: Install Nginx Ingress Controller
        run: |
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --set controller.service.type=LoadBalancer \
            --set controller.ingressClassResource.name=nginx \
            --set controller.ingressClassResource.controllerValue="k8s.io/ingress-nginx" \
            --wait \
            --timeout 5m

      - name: Wait for LoadBalancer IP
        run: |
          echo "Waiting for LoadBalancer IP assignment..."
          timeout 300s bash -c 'until kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath="{.status.loadBalancer.ingress[0].ip}" | grep -q "."; do sleep 5; done'
          EXTERNAL_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "External IP: $EXTERNAL_IP"
          echo "external_ip=$EXTERNAL_IP" >> $GITHUB_ENV

      - name: Comprehensive namespace management
        run: |
          echo "=== Namespace Management ==="
          kubectl delete namespace lbg-ns --force --grace-period=0 --ignore-not-found=true || true
          sleep 30
          kubectl create namespace lbg-ns
          kubectl get namespace lbg-ns

      - name: Create ACR pull secret
        run: |
          kubectl create secret docker-registry acr-secret \
            --namespace lbg-ns \
            --docker-server=${{ env.ACR_NAME }}.azurecr.io \
            --docker-username=${{ steps.get_acr_credentials.outputs.acr_username }} \
            --docker-password=${{ steps.get_acr_credentials.outputs.acr_password }} \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy to AKS using Helm
        run: |
          cd kubernetes/helm
          
          echo "=== Helm Deployment ==="
          
          # Template for verification
          helm template lbg-app . \
            --namespace lbg-ns \
            -f values-dev.yml \
            --set patientService.tag=${{ github.sha }} \
            --set appointmentService.tag=${{ github.sha }} \
            --set image.registry=${{ env.ACR_NAME }}.azurecr.io
          
          # Install/Upgrade
          helm upgrade --install lbg-app . \
            --namespace lbg-ns \
            --wait \
            --timeout 20m \
            -f values-dev.yml \
            --set patientService.tag=${{ github.sha }} \
            --set appointmentService.tag=${{ github.sha }} \
            --set image.registry=${{ env.ACR_NAME }}.azurecr.io \
            --atomic
          
          echo "Helm deployment completed successfully"

      - name: Verify deployment
        run: |
          echo "=== Deployment Verification ==="
          kubectl get all -n lbg-ns
          kubectl get ingress -n lbg-ns

      - name: Get Browser Access URLs
        run: |
          EXTERNAL_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "üéâ DEPLOYMENT SUCCESSFUL!"
          echo ""
          echo "üì± BROWSER ACCESS INFORMATION:"
          echo "================================"
          echo "External IP: $EXTERNAL_IP"
          echo ""
          echo "üìç Add this to your /etc/hosts file:"
          echo "$EXTERNAL_IP lbg-app.dev.local"
          echo ""
          echo "üåê Access your services in browser:"
          echo "   Patient Service:    http://lbg-app.dev.local/"
          echo "   Appointment Service: http://lbg-app.dev.local/appointments"
          echo "   Health Check:       http://lbg-app.dev.local/health"

      - name: Run comprehensive health checks
        run: |
          echo "=== Running Health Checks ==="
          
          # Wait for pods to be ready
          echo "Waiting for pods to be ready..."
          kubectl wait --for=condition=ready pod -l app=patient-service -n lbg-ns --timeout=300s
          kubectl wait --for=condition=ready pod -l app=appointment-service -n lbg-ns --timeout=300s
          
          # Get external IP
          EXTERNAL_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "External IP: $EXTERNAL_IP"
          
          # Wait for ingress
          sleep 30
          
          # Test applications inside pods first
          echo "Testing applications inside pods..."
          kubectl exec -n lbg-ns deployment/patient-service -- curl -s http://localhost:3000/health && echo "‚úÖ Patient service internal: OK" || echo "‚ùå Patient service internal: FAILED"
          kubectl exec -n lbg-ns deployment/appointment-service -- curl -s http://localhost:3001/health && echo "‚úÖ Appointment service internal: OK" || echo "‚ùå Appointment service internal: FAILED"
          
          # Test through ingress
          echo "Testing through ingress..."
          if curl -s -f -m 10 -H "Host: lbg-app.dev.local" http://$EXTERNAL_IP/health; then
            echo "‚úÖ Health check: SUCCESS"
          else
            echo "‚ùå Health check: FAILED"
          fi
          
          if curl -s -f -m 10 -H "Host: lbg-app.dev.local" http://$EXTERNAL_IP/; then
            echo "‚úÖ Root endpoint: SUCCESS"
          else
            echo "‚ùå Root endpoint: FAILED"
          fi
          
          if curl -s -f -m 10 -H "Host: lbg-app.dev.local" http://$EXTERNAL_IP/appointments; then
            echo "‚úÖ Appointments endpoint: SUCCESS"
          else
            echo "‚ùå Appointments endpoint: FAILED"
          fi

  cleanup:
    runs-on: ubuntu-latest
    if: always()
    needs: [deploy-to-dev]
    steps:
      - name: Cleanup Docker images
        run: |
          docker system prune -f